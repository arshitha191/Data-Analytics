{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">  Generate Parts of Speech tags using various python libraries </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> Generating POS tags using Polyglot library </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Download polyglot POS model for English language\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1. Slovene                    2. French                     3. Hungarian                \n",
      "  4. Swedish                    5. Spanish; Castilian         6. Portuguese               \n",
      "  7. Indonesian                 8. English                    9. German                   \n",
      " 10. Danish                    11. Czech                     12. Bulgarian                \n",
      " 13. Italian                   14. Irish                     15. Dutch                    \n",
      " 16. Finnish                  \n"
     ]
    }
   ],
   "source": [
    "from polyglot.downloader import downloader\n",
    "print(downloader.supported_languages_table(\"pos2\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load POS model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[polyglot_data] Downloading package embeddings2.en to\n",
      "[polyglot_data]     /home/jalaj/polyglot_data...\n",
      "[polyglot_data]   Package embeddings2.en is already up-to-date!\n",
      "[polyglot_data] Downloading package pos2.en to\n",
      "[polyglot_data]     /home/jalaj/polyglot_data...\n",
      "[polyglot_data]   Package pos2.en is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from polyglot.downloader import downloader\n",
    "downloader.download(\"embeddings2.en\")\n",
    "downloader.download(\"pos2.en\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polyglot\n",
    "from polyglot.text import Text, Word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect the language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language Detected: Code=fr, Name=French\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = Text(\"Bonjour, Mesdames.\")\n",
    "print(\"Language Detected: Code={}, Name={}\\n\".format(text.language.code, text.language.name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization of the sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Beautiful', 'is', 'better', 'than', 'ugly', '.', 'Explicit', 'is', 'better', 'than', 'implicit', '.', 'Simple', 'is', 'better', 'than', 'complex', '.']\n"
     ]
    }
   ],
   "source": [
    "words_list = Text(\"Beautiful is better than ugly. \"\n",
    "           \"Explicit is better than implicit. \"\n",
    "           \"Simple is better than complex.\")\n",
    "print(words_list.words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Generate POS tags for given sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = \"\"\"We will meet at eight o'clock on Thursday morning.\"\"\"\n",
    "text = Text(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('We', 'PRON'),\n",
       " ('will', 'AUX'),\n",
       " ('meet', 'VERB'),\n",
       " ('at', 'ADP'),\n",
       " ('eight', 'NUM'),\n",
       " (\"o'clock\", 'NOUN'),\n",
       " ('on', 'ADP'),\n",
       " ('Thursday', 'PROPN'),\n",
       " ('morning', 'NOUN'),\n",
       " ('.', 'PUNCT')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text.pos_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word            POS Tag\n",
      "------------------------------\n",
      "We              PRON\n",
      "will            AUX\n",
      "meet            VERB\n",
      "at              ADP\n",
      "eight           NUM\n",
      "o'clock         NOUN\n",
      "on              ADP\n",
      "Thursday        PROPN\n",
      "morning         NOUN\n",
      ".               PUNCT\n"
     ]
    }
   ],
   "source": [
    "print(\"{:<16}{}\".format(\"Word\", \"POS Tag\")+\"\\n\"+\"-\"*30)\n",
    "for word, tag in text.pos_tags:\n",
    "    print(u\"{:<16}{:>2}\".format(word, tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word            POS Tag\n",
      "------------------------------\n",
      "This            DET\n",
      "is              VERB\n",
      "a               DET\n",
      "car             NOUN\n"
     ]
    }
   ],
   "source": [
    "text = Text(\"This is a car\")\n",
    "text.pos_tags\n",
    "print(\"{:<16}{}\".format(\"Word\", \"POS Tag\")+\"\\n\"+\"-\"*30)\n",
    "for word, tag in text.pos_tags:\n",
    "    print(u\"{:<16}{:>2}\".format(word, tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word            POS Tag\n",
      "------------------------------\n",
      "Alexander       PROPN\n",
      "the             DET\n",
      "Great           PROPN\n",
      ".               PUNCT\n",
      ".               PUNCT\n",
      ".               PUNCT\n",
      "!               PUNCT\n"
     ]
    }
   ],
   "source": [
    "text = Text(\"Alexander the Great...!\")\n",
    "text.pos_tags\n",
    "print(\"{:<16}{}\".format(\"Word\", \"POS Tag\")+\"\\n\"+\"-\"*30)\n",
    "for word, tag in text.pos_tags:\n",
    "    print(u\"{:<16}{:>2}\".format(word, tag))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word            POS Tag\n",
      "------------------------------\n",
      "Alexander       PROPN\n",
      "the             DET\n",
      "Great           PROPN\n",
      ",               PUNCT\n",
      "was             VERB\n",
      "a               DET\n",
      "king            NOUN\n",
      "of              ADP\n",
      "the             DET\n",
      "ancient         ADJ\n",
      "Greek           ADJ\n",
      "kingdom         NOUN\n",
      "of              ADP\n",
      "Macedon         PROPN\n",
      ".               PUNCT\n"
     ]
    }
   ],
   "source": [
    "text = Text(\"Alexander the Great, was a king of the ancient Greek kingdom of Macedon.\")\n",
    "text.pos_tags\n",
    "print(\"{:<16}{}\".format(\"Word\", \"POS Tag\")+\"\\n\"+\"-\"*30)\n",
    "for word, tag in text.pos_tags:\n",
    "    print(u\"{:<16}{:>2}\".format(word, tag))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> Generating POS tags using Spacy library </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Generate POS tag for given sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                            Word Category                   POS Tag\n",
      "--------------------------------------------------------------------------------\n",
      "Apple                           PROPN                           NNP\n",
      "is                              VERB                            VBZ\n",
      "looking                         VERB                            VBG\n",
      "at                              ADP                             IN\n",
      "buying                          VERB                            VBG\n",
      "U.K.                            PROPN                           NNP\n",
      "startup                         NOUN                            NN\n",
      "for                             ADP                             IN\n",
      "$                               SYM                             $\n",
      "1                               NUM                             CD\n",
      "billion                         NUM                             CD\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'Apple is looking at buying U.K. startup for $1 billion')\n",
    "print(\"{:<32}{:<32}{}\".format(\"Word\", \"Word Category\", \"POS Tag\")+\"\\n\"+\"-\"*80)\n",
    "for token in doc:\n",
    "    #print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,token.shape_, token.is_alpha, token.is_stop)\n",
    "    print(u\"{:<32}{:<32}{}\".format(token.text,token.pos_, token.tag_))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 align=\"center\"> Why do we need to develop our own POS tagger? </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "* Dealing with domain specific terminology\n",
    "\n",
    "* Dealing with ambiguity \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word                            Word Category                   POS Tag\n",
      "--------------------------------------------------------------------------------\n",
      "The                             DET                             DT\n",
      "name                            NOUN                            NN\n",
      "of                              ADP                             IN\n",
      "your                            ADJ                             PRP$\n",
      "medicine                        NOUN                            NN\n",
      "is                              VERB                            VBZ\n",
      "Paracetamol                     PROPN                           NNP\n",
      "500                             NUM                             CD\n",
      "mg                              ADJ                             JJ\n",
      "Tablets                         NOUN                            NNS\n",
      "(                               PUNCT                           -LRB-\n",
      "called                          VERB                            VBN\n",
      "paracetamol                     NOUN                            NN\n",
      "throughout                      ADP                             IN\n",
      "this                            DET                             DT\n",
      "leaflet                         NOUN                            NN\n",
      ")                               PUNCT                           -RRB-\n",
      ".                               PUNCT                           .\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'The name of your medicine is Paracetamol 500mg Tablets (called paracetamol throughout this leaflet). ')\n",
    "print(\"{:<32}{:<32}{}\".format(\"Word\", \"Word Category\", \"POS Tag\")+\"\\n\"+\"-\"*80)\n",
    "for token in doc:\n",
    "    #print(token.text, token.lemma_, token.pos_, token.tag_, token.dep_,token.shape_, token.is_alpha, token.is_stop)\n",
    "    print(u\"{:<32}{:<32}{}\".format(token.text,token.pos_, token.tag_)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
